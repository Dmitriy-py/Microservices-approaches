# Домашнее задание к занятию «Микросервисы: подходы»

## ` Дмитрий Климов `

## Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры. Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.

## Задача 1: Обеспечить разработку

### Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

### Решение должно соответствовать следующим требованиям:

  * облачная система;
  * система контроля версий Git;
  * репозиторий на каждый сервис;
  * запуск сборки по событию из системы контроля версий;
  * запуск сборки по кнопке с указанием параметров;
  * возможность привязать настройки к каждой сборке;
  * возможность создания шаблонов для различных конфигураций сборок;
  * возможность безопасного хранения секретных данных (пароли, ключи доступа);
  * несколько конфигураций для сборки из одного репозитория;
  * кастомные шаги при сборке;
  * собственные докер-образы для сборки проектов;
  * возможность развернуть агентов сборки на собственных серверах;
  * возможность параллельного запуска нескольких сборок;
  * возможность параллельного запуска тестов.

### Обоснуйте свой выбор.

## Ответ:

## Предложение по организации инфраструктуры для разработки микросервисов

### Введение

Для обеспечения эффективной разработки, непрерывной интеграции (CI) и непрерывной поставки (CD) в условиях микросервисной архитектуры, а также с учетом заданных требований (облачность, Git, кастомизация, безопасность), я предлагаю использовать комбинацию инструментов, сфокусированных на облачных нативных практиках и автоматизации.

Основу решения составит связка **GitLab** (как единая платформа для Git, CI/CD и артефактов) и **Kubernetes** (для гибкого развертывания агентов сборки и эксплуатации).

---

### Задача 1: Обеспечение процесса разработки (CI/CD)

#### Предлагаемое решение: GitLab + GitLab Runners (на базе Kubernetes) + Helm/Kustomize

| Компонент | Продукт | Назначение и реализация |
| :--- | :--- | :--- |
| **Система контроля версий (SCM)** | **GitLab (SaaS или Self-Managed)** | Единый центр для хранения исходного кода, управления репозиториями, запросами на слияние (Merge Requests) и запуска пайплайнов. |
| **Непрерывная Интеграция/Поставка (CI/CD)** | **GitLab CI/CD** | Движок для автоматизации сборки, тестирования и развертывания. |
| **Агенты Сборки (Runners)** | **GitLab Runners, развернутые в режиме Kubernetes Executor** | Обеспечивают выполнение задач CI/CD. Использование Kubernetes Executor позволяет динамически создавать и удалять поды (временные контейнеры) для каждой сборки. |
| **Хранение артефактов и образов** | **GitLab Container Registry / AWS ECR / Docker Hub** | Реестр для хранения собранных Docker-образов. |
| **Управление конфигурациями (Deploy)** | **Helm / Kustomize** | Инструменты для шаблонизации манифестов Kubernetes для разных сред (Dev, Stage, Prod). |
| **Хранение секретов** | **GitLab Secrets Management (или интеграция с HashiCorp Vault / AWS Secrets Manager)** | Безопасное хранение чувствительных данных. |

---

### Обоснование выбора и соответствие требованиям

#### 1. Облачная система

*   **GitLab:** Может быть использован как полностью облачный сервис (GitLab.com) или развернут на облачных IaaS/PaaS (AWS, Azure, GCP) как Self-Managed инсталляция.
*   **Kubernetes (K8s):** Является стандартом де-факто для облачно-нативных приложений, обеспечивая масштабируемость и переносимость.

#### 2. Система контроля версий Git и Репозиторий на каждый сервис

*   **GitLab** нативно поддерживает Git. Каждый микросервис будет размещен в собственном приватном репозитории GitLab, что соответствует принципу "один репозиторий — один сервис".

#### 3. Запуск сборки по событию из системы контроля версий

*   **GitLab CI/CD** по умолчанию настроен на запуск пайплайна (`.gitlab-ci.yml`) при любом пуше или мерже в репозиторий.

#### 4. Запуск сборки по кнопке с указанием параметров

*   **GitLab CI/CD (Manual Jobs & Variables):** Пайплайны могут быть запущены вручную ("Run Pipeline") с возможностью передачи **переменных (Variables)**, которые могут влиять на логику сборки (например, выбрать целевую среду, версию развертывания).

#### 5. Возможность привязать настройки к каждой сборке

*   Настройки пайплайна (переменные окружения, теги Docker-образов, целевые среды) определяются в `variables:` секции в `.gitlab-ci.yml` или передаются вручную при запуске.

    Пример в `.gitlab-ci.yml`:
    ```yaml
    variables:
      SERVICE_VERSION: "1.0.0"
      DEPLOY_ENVIRONMENT: "dev"

    build:
      stage: build
      script:
        - echo "Building service ${SERVICE_VERSION} for environment ${DEPLOY_ENVIRONMENT}"
        # ...
    ```

#### 6. Возможность создания шаблонов для различных конфигураций сборок

*   **GitLab CI/CD Templates:** Позволяют создавать повторно используемые части пайплайнов (например, стандартные этапы сборки Docker, прогона тестов) и включать их в конфигурацию конкретного сервиса с помощью директивы `include:`. Это критически важно для стандартизации в среде микросервисов.

    Пример `gitlab-ci-templates/build-java.yml`:
    ```yaml
    .java-build-template:
      stage: build
      image: maven:3-jdk-11
      script:
        - mvn clean install -DskipTests
      artifacts:
        paths:
          - target/*.jar
    ```

    Использование в `.gitlab-ci.yml` сервиса:
    ```yaml
    include:
      - project: 'my-org/gitlab-ci-templates'
        ref: main
        file: '/build-java.yml'

    java_backend_build:
      extends: .java-build-template
      # Дополнительные настройки для этого сервиса
    ```

#### 7. Возможность безопасного хранения секретных данных

*   **GitLab CI/CD Variables:** Позволяют хранить секреты (например, ключи доступа к облачным провайдерам, пароли к реестрам) как "protected" и "masked" переменные, доступные только для определенных веток или ручных запусков.
*   *Для более сложного управления:* Интеграция с **HashiCorp Vault** или нативными облачными менеджерами секретов (AWS Secrets Manager) через специальные шаги в пайплайне, использующие аутентификацию по JWT токену или OIDC.

#### 8. Несколько конфигураций для сборки из одного репозитория

*   **GitLab CI/CD (Rules/Only/When):** Используя условия `rules:` или старые `only/except`, можно определить, какие части пайплайна должны выполняться в зависимости от ветки (например, `main` запускает релиз, `feature/*` запускает только юнит-тесты), тега или переданных переменных.

    Пример:
    ```yaml
    deploy_production:
      stage: deploy
      script:
        - deploy-to-prod.sh
      rules:
        - if: '$CI_COMMIT_BRANCH == "main"' # Запуск только для ветки main
          when: manual # Ручной запуск
          allow_failure: false
        - if: '$CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+$/' # Запуск при пуше тега
          when: on_success
    ```

#### 9. Кастомные шаги при сборке

*   **Dockerfile и Скрипты:** Каждый шаг в GitLab CI/CD — это команда или скрипт, выполняемый внутри агента. Это позволяет использовать любые кастомные bash-скрипты, Python-скрипты или вызовы утилит.

    Пример:
    ```yaml
    custom_step:
      stage: deploy
      image: python:3.9-slim
      script:
        - python custom_deployment_script.py --env ${DEPLOY_ENVIRONMENT}
        - echo "Custom step finished."
    ```

#### 10. Собственные докер-образы для сборки проектов

*   **Custom Base Images:** GitLab Runners, работающие на K8s, будут использовать стандартные образы (например, `maven:3-jdk-11`). Однако, для сложных сборок можно создать **собственный базовый образ Docker** (например, с предустановленными инструментами специфики компании) и использовать его в качестве образа для выполнения конкретного задания CI/CD.

    Пример `Dockerfile`:
    ```dockerfile
    FROM alpine/git:latest
    RUN apk add --no-cache openssh-client curl jq
    # Дополнительные инструменты
    ```

    Использование в `.gitlab-ci.yml`:
    ```yaml
    my_custom_build:
      stage: build
      image: registry.example.com/my-org/custom-ci-tools:latest # Ваш собственный образ
      script:
        - my-custom-tool --version
        - git clone ssh://git@some-internal-repo.com/project.git
    ```

#### 11. Возможность развернуть агентов сборки на собственных серверах

*   **GitLab Runners (Self-Hosted):** Мы регистрируем **собственные GitLab Runners**, которые подключаются к центральному GitLab Server. Эти Runners настраиваются с использованием **Kubernetes Executor**. Таким образом, агенты (поды K8s) запускаются в кластере, который может быть развернут на собственном оборудовании (On-Premise) или в частном облаке компании, сохраняя при этом централизованное управление через GitLab.

    ```bash
    # Пример установки GitLab Runner с Kubernetes Executor
    helm repo add gitlab https://charts.gitlab.io
    helm repo update
    helm install --namespace gitlab-runner --create-namespace gitlab-runner gitlab/gitlab-runner \
      --set gitlabUrl=https://gitlab.com/ \
      --set runnerRegistrationToken="YOUR_RUNNER_TOKEN" \
      --set rbac.create=true \
      --set serviceAccount.create=true \
      --set runners.config="""
    [[runners]]
      [runners.kubernetes]
        namespace = "gitlab-runner"
        image = "ubuntu:20.04" # Образ по умолчанию для подов
        cpu_request = "100m"
        memory_request = "128Mi"
        cpu_limit = "500m"
        memory_limit = "512Mi"
      # ...
    """
    ```

#### 12. Возможность параллельного запуска нескольких сборок

*   **GitLab Runners:** Одновременно работающие Runner'ы могут обрабатывать очереди заданий. Если несколько сервисов пушат код одновременно, их пайплайны будут выполняться параллельно (при условии наличия доступных ресурсов в K8s и настроенных `concurrent` лимитов на Runner'е). Каждый пайплайн или отдельное задание в пайплайне (если ресурсы позволяют) будет запускаться в своем собственном поде Kubernetes.

#### 13. Возможность параллельного запуска тестов

*   **GitLab CI/CD (Parallel Jobs):** Внутри одного пайплайна можно разделить задания на несколько параллельных стадий или использовать ключевое слово `parallel:` для распараллеливания одного задания.

    Пример параллельного запуска тестов:
    ```yaml
    unit_tests:
      stage: test
      image: node:16
      script:
        - npm install
        - npm test
      parallel: 3 # Запуск 3 параллельных заданий, каждое со своим тестом или частью тестов (например, через test-splits)
    ```

    *   **Внутри одного задания:** Тестовые фреймворки (Jest, JUnit, Pytest-xdist) могут быть настроены на распределение тестов по потокам или процессам внутри одного контейнера сборки.

---

### Заключение

Предложенная связка **GitLab + Kubernetes Runners** обеспечивает **единую платформу** для всех процессов разработки и эксплуатации (SCM, CI, Registry, Secrets Management), высокую степень **кастомизации** через шаблоны и скрипты, а также гарантирует **гибкое масштабирование** за счет динамического выделения ресурсов через Kubernetes для выполнения сборочных задач. Это соответствует лучшим практикам DevOps для построения облачно-нативных систем.

## Задача 2: Логи

### Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре. Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

### Решение должно соответствовать следующим требованиям:

  * сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
  * минимальные требования к приложениям, сбор логов из stdout;
  * гарантированная доставка логов до центрального хранилища;
  * обеспечение поиска и фильтрации по записям логов;
  * обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
  * возможность дать ссылку на сохранённый поиск по записям логов.

### Обоснуйте свой выбор.

## Ответ:

## Предложение по организации системы сбора и анализа логов

### Введение

В микросервисной архитектуре, где количество инстансов сервисов может исчисляться сотнями, ручной сбор логов с каждого хоста невозможен. Для решения этой задачи я предлагаю использовать индустриальный стандарт — стек **EFK (Elasticsearch, Fluent Bit/Fluentd, Kibana)**. Это гибкое, масштабируемое решение, которое идеально ложится на контейнеризированную среду (Kubernetes) и облачную инфраструктуру.

---

### Сбор и анализ логов

#### Предлагаемое решение: Стек EFK (Elasticsearch, Fluent Bit, Kibana)

| Компонент | Продукт | Назначение и реализация |
| :--- | :--- | :--- |
| **Центральное хранилище и поиск** | **Elasticsearch** | Распределенная поисковая и аналитическая система. Хранит индексы логов, обеспечивает мгновенный полнотекстовый поиск и фильтрацию. |
| **Сборщик логов (Агент)** | **Fluent Bit** | Легковесный агент, устанавливаемый на каждый хост (в Kubernetes — как DaemonSet). Читает логи из stdout контейнеров, обогащает их метаданными и отправляет в хранилище. |
| **Визуализация и UI** | **Kibana** | Веб-интерфейс для работы с данными из Elasticsearch. Позволяет разработчикам искать логи, строить дашборды и обмениваться ссылками на результаты поиска. |
| **Гарантия доставки** | **Fluent Bit Buffering** | Механизм промежуточного хранения логов на диске/в памяти агента для предотвращения потери данных при сбоях сети. |

---

### Обоснование выбора и соответствие требованиям

#### 1. Сбор логов в центральное хранилище со всех хостов
*   **Реализация:** Fluent Bit запускается на каждом узле кластера. Он собирает логи со всех контейнеров и системных сервисов, работающих на данном хосте, и пересылает их в единый кластер Elasticsearch. Это обеспечивает централизацию данных вне зависимости от количества серверов.

#### 2. Минимальные требования к приложениям (сбор из stdout)
*   **Реализация:** Приложения не должны знать о системе логирования. Они просто пишут логи в стандартный поток вывода (`stdout`) и поток ошибок (`stderr`). Docker/Containerd записывает эти потоки в JSON-файлы на хосте, которые Fluent Bit автоматически подхватывает. Это соответствует принципу "12-factor app".

#### 3. Гарантированная доставка логов
*   **Реализация:** Fluent Bit поддерживает механизмы **Retry** (повторная отправка при ошибках связи) и **Buffering** (буферизация данных). В случае кратковременного падения Elasticsearch или сетевого сбоя, логи будут сохраняться в локальном буфере (на диске или в RAM) и будут отправлены сразу после восстановления соединения.

#### 4. Обеспечение поиска и фильтрации
*   **Реализация:** Elasticsearch индексирует каждое входящее сообщение. Это позволяет выполнять сложнейшие запросы: поиск по конкретному `service_name`, по уровню логирования (`ERROR`, `WARN`), по временному интервалу или по вхождению подстроки в теле сообщения. Поддерживается мощный язык запросов KQL (Kibana Query Language).

#### 5. Пользовательский интерфейс и доступ разработчиков
*   **Реализация:** **Kibana** предоставляет удобный интерфейс (раздел Discover). В Elastic Stack (в базовой бесплатной версии) встроена система **RBAC (Role-Based Access Control)**. Можно создать роли для разработчиков, которые позволят им видеть логи только своих сервисов или только определенных сред (например, `dev` и `staging`), ограничивая доступ к `production`.

#### 6. Возможность дать ссылку на сохранённый поиск
*   **Реализация:** Kibana — это полноценное веб-приложение. Каждый поисковый запрос, примененный фильтр или выбранный временной диапазон отображается в URL-адресе страницы.
    *   **Short URLs:** Kibana позволяет генерировать "короткие ссылки" на текущее состояние поиска.
    *   **Saved Searches:** Разработчик может сохранить настроенный фильтр (например, "Ошибки сервиса заказов за час") и поделиться ссылкой на этот именованный поиск с коллегами.

---

### Схема взаимодействия компонентов

1.  **Приложение:** Пишет лог в `stdout`.
2.  **Container Runtime (Docker/Containerd):** Перехватывает `stdout` и записывает в файл `/var/log/pods/.../*.log`.
3.  **Fluent Bit (Agent):** 
    *   Следит за файлами логов.
    *   Парсит JSON (если логи в JSON-формате).
    *   Добавляет метаданные Kubernetes (имя пода, неймспейс, ID контейнера, имя хоста).
    *   Отправляет данные в Elasticsearch по протоколу HTTP/HTTPS.
4.  **Elasticsearch (Storage):** Принимает данные, индексирует их и сохраняет в шарды.
5.  **Kibana (UI):** Обращается к API Elasticsearch для выполнения поисковых запросов пользователя и отображения результатов в браузере.

### Почему не другие решения?
*   **Logstash:** Слишком тяжеловесен для запуска на каждом хосте (потребляет много RAM). Fluent Bit значительно легче и быстрее.
*   **Loki (Grafana Stack):** Отличное решение, но оно индексирует только лейблы (метаданные), а не сам текст логов. Если требуется сложный полнотекстовый поиск по телу сообщения (например, по стектрейсу ошибки), Elasticsearch справляется с этим лучше и быстрее.

Задача 3: Мониторинг
Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре. Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:

сбор метрик со всех хостов, обслуживающих систему;
сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
сбор метрик, специфичных для каждого сервиса;
пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.
Обоснуйте свой выбор.

## Ответ:

## Предложение по организации системы мониторинга

### Введение

Для микросервисной архитектуры, особенно развернутой в облаке или Kubernetes, стандартом де-факто является связка **Prometheus** и **Grafana**. Это решение обеспечивает мощный сбор метрик по модели pull (опрос), гибкий язык запросов и лучшую в классе визуализацию.

---

### Предлагаемое решение: Prometheus Stack (Prometheus, Grafana, Exporters)

| Компонент | Продукт | Назначение и реализация |
| :--- | :--- | :--- |
| **Сбор и хранение метрик** | **Prometheus** | Система мониторинга и база данных временных рядов (TSDB). Самостоятельно опрашивает цели (targets) и хранит данные. |
| **Агент сбора метрик хоста** | **Node Exporter** | Утилита, устанавливаемая на каждый хост. Собирает данные о железе и ОС (CPU, RAM, Disk, Network). |
| **Сбор метрик контейнеров** | **cAdvisor** | Анализирует потребление ресурсов контейнерами. В Kubernetes встроен в Kubelet. |
| **Прикладные метрики** | **Prometheus Client Libraries** | Библиотеки для кода приложений (Java, Go, Python и др.), позволяющие сервисам отдавать специфичные метрики (кол-во заказов, время обработки запроса). |
| **Визуализация и UI** | **Grafana** | Платформа для аналитики и мониторинга. Подключается к Prometheus как к источнику данных для построения дашбордов. |

---

### Обоснование выбора и соответствие требованиям

#### 1. Сбор метрик со всех хостов
*   **Реализация:** На каждом хосте (физическом или виртуальном) разворачивается **Node Exporter**. Prometheus настраивается на автоматическое обнаружение этих хостов (Service Discovery) и опрашивает их с заданным интервалом.

#### 2. Метрики состояния ресурсов хостов (CPU, RAM, HDD, Network)
*   **Реализация:** **Node Exporter** из коробки предоставляет сотни метрик:
    *   `node_cpu_seconds_total` (CPU);
    *   `node_memory_MemAvailable_bytes` (RAM);
    *   `node_filesystem_avail_bytes` (HDD);
    *   `node_network_receive_bytes_total` (Network).

#### 3. Метрики потребляемых ресурсов для каждого сервиса
*   **Реализация:** Если сервисы работают в контейнерах, **cAdvisor** собирает детальную информацию по каждому контейнеру:
    *   `container_cpu_usage_seconds_total` — использование процессора сервисом;
    *   `container_memory_usage_bytes` — использование оперативной памяти;
    *   Аналогичные метрики доступны для сети и дисковых операций ввода-вывода внутри контейнера.

#### 4. Сбор метрик, специфичных для каждого сервиса
*   **Реализация:** Разработчики интегрируют в микросервисы **Prometheus Client Library**. Сервис открывает HTTP-эндпоинт (обычно `/metrics`), где в формате Prometheus публикует внутренние бизнес-метрики или технические показатели (например, размер очереди сообщений или количество активных сессий).

#### 5. Интерфейс для запросов и агрегации информации
*   **Реализация:** Prometheus использует язык запросов **PromQL**. Он позволяет выполнять сложные вычисления "на лету":
    *   Агрегировать данные (например, среднее потребление CPU по всему кластеру или суммарный RPS по всем инстансам одного сервиса).
    *   Вычислять процентили (например, 95-й процентиль времени ответа API).
    *   Использовать функции прогнозирования (например, когда закончится место на диске).

#### 6. Настройка панелей (Dashboards) для отслеживания состояния
*   **Реализация:** **Grafana** является идеальным инструментом для этого.
    *   **Различные панели:** Позволяет создавать графики, таблицы, "тепловые карты", статусные индикаторы.
    *   **Шаблонизация:** Можно создать один дашборд и переключаться между микросервисами или хостами с помощью выпадающего списка (Variables).
    *   **Marketplace:** Существует огромное количество готовых официальных дашбордов для Node Exporter, Kubernetes и популярных баз данных.

---

### Схема взаимодействия компонентов

1.  **Node Exporter / cAdvisor / Микросервис:** Экспортируют метрики в текстовом формате через HTTP.
2.  **Prometheus:**
    *   По расписанию (например, каждые 15 сек) "забирает" (scrape) метрики из всех источников.
    *   Сохраняет их в свою базу данных.
    *   Проверяет правила алертинга (если настроены) и отправляет уведомления.
3.  **Grafana:**
    *   Отправляет PromQL-запросы к Prometheus при открытии дашборда пользователем.
    *   Отрисовывает полученные данные в удобном графическом виде.
4.  **Пользователь (DevOps/Разработчик):** Использует Grafana для визуального мониторинга и Prometheus UI для отладки конкретных запросов к метрикам.

### Почему не Zabbix или Nagios?
*   **Zabbix/Nagios** сложнее масштабируются в динамических средах (где контейнеры постоянно создаются и удаляются).
*   **Prometheus** специально спроектирован для микросервисов: он лучше работает с "эфемерными" целями и обладает мощнейшим языком агрегации (PromQL), который незаменим, когда нужно видеть общую картину по десяткам инстансов одного приложения.










